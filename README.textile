h1. About

Transform MAB-XML to JSON for Elasticsearch indexing with "Metafacture":https://github.com/culturegraph/metafacture-core/wiki used by the upcoming API 2.0 for "lobid resource":http://lobid.org/.

This repo is going to substitue big parts of https://github.com/lobid/lodmill .

The aim in API 2.0 is to make things easier, i.e.:
* get rid of hadoop
* concentrating only on lobid-resources (and not also gnd, lobid-organisations etc.)

h1. Build

"!https://secure.travis-ci.org/hbz/lobid-resources.png?branch=master!":https://travis-ci.org/hbz/lobid-resources

Prerequisites: Java 8, Maven 3; verify with @mvn -version@

Create and change into a folder where you want to store the projects:

* @mkdir ~/git ; cd ~/git@

Build the hbz metafacture-core fork:

* @git clone https://github.com/hbz/metafacture-core.git@
* @cd metafacture-core@
* @mvn clean install -DskipTests@
* @cd ..@

Build lobid-rdf-to-json:

* @git clone https://github.com/hbz/lobid-rdf-to-json.git@
* @cd lobid-resources@
* @mvn clean install -DskipTests@
* @cd ..@

Build lobid-resources:

* @git clone https://github.com/hbz/lobid-resources.git@
* @cd lobid-resources@
* @mvn clean install@

See the @.travis.yml@ file for details on the CI config used by Travis.

h1. Example of getting the data

In the online test the data is indexed to a living elasticsearch instance.
This instance is only reachable within our internally network, thus this test
must be executed manually. Then elasticsearch can be looked up like this:

http://lobid.org/resources/HT002619538

For querying it you can use the elasticsearch query DSl, like:

http://lobid.org/resources?q=title:Mobydick

The result shows the data which also "Hbz01MabXml2ElasticsearchLobidTest.java":https://github.com/hbz/lobid-resources/blob/master/src/test/java/org/lobid/resources/Hbz01MabXml2ElasticsearchLobidTest.java produces.

h1. Developer instructions

This section explains how to make a successful build after changing the transformations,
how to include the JSON-LD dependency and updating its context, and how to index the data.

h2. Changing transformations

After changing the "morph":https://github.com/hbz/lobid-resources/blob/master/src/main/resources/morph-hbz01-to-lobid.xml the build must be executed:

@mvn clean install@

This may end in a *BUILD SUCCESS* message, meaning that the tested resources don't reflect the changes.
In this case you should add an Aleph-MabXml resource to "hbz01XmlClobs.tar.bz2":https://github.com/hbz/lobid-resources/blob/master/src/test/resources/hbz01XmlClobs.tar.bz2 that _would_ reflect your changes. Do like this:

@cd src/test/resources; rm -rf hbz01XmlClobs; tar xfj hbz01XmlClobs; xmllint --format http://beta.lobid.org/hbz01/HT018895767 > hbhbz01XmlClobs/HT018895767; tar cfj hbz01XmlClobs.tar.bz2 hbz01XmlClobs; cd -@

If the build ends with *BUILD FAILURE* the newly generated data isn't equal to the test resources.
This is a good thing because you wanted the change. Now you must approve the new outcome.
Let's see what has changed:

@git status@

Let's make a diff on the changes, e.g. all JSON-LD documents:

@git diff src/test/resources/jsonld/@

If you are satisfied with the changes, go ahead and add and commit them:

@git add src/test/resources/jsonld/; git commit@

Do this respectivly for all other test files (Ntriples).
If you've added and commited everything, check again if all is ok:

@mvn clean install@

This should result in *BUILD SUCCESS*. Push your changes. You're done :)

h2. Internal hbz Instructions

This is for hbz committers only. It's assumed that you reside in the internal hbz net.

h3. Dependency to lobid-rdf-to-json

The dependency is configured using the pom.xml. As version you use a commit hash of
the "lobid-rdf-to-json repo":https://github.com/hbz/lobid-rdf-to-json. Via "jitpack":https://jitpack.io/ a maven artefact is built on demand and installed to the local maven repo.

Also, if you changed the JSON-LD context, don't forget to upload that onto the webserver:

* @scp ./src/main/resources/context.json lobid@@@emphytos:/usr/local/lobid/src/lobid.org/download/contextTmp.json@

h3. Elasticsearch index

This is about the building of the production index as well as the small test index.

h4. Production

All automation is configured at one central crontab entry: _hduser@weywot1_ .
This is your starting point for tracing what scripts are triggered on what server
at which time. All is logged, see the crontab entries resp. the scripts.

Like with the old (and still productive) lobid index, a weekly fulldump
index is build on Saturdays. This is the base for the daily incremental updates.
Have a look at "both source data, base and daily updates":http://lobid.org/download/dumps/DE-605/mabxml/.
Building the full index takes around 12 hours. The finished index is aliased
to _resources-staging_. This is manually to be tested. If it's ok, the
index is switched by simply renaming this alias to _resources_ . Both aliases are
reflected in the lookup-URI (e.g. http://lobid.org/resources/HT015082724 vs
http://lobid.org/resources-staging/HT015082724 resp. internal ES URI
@http://gaia.hbz-nrw.de:9200/resources/_all/HT015082724@ and
@http://gaia.hbz-nrw.de:9200/resources-staging/_all/HT015082724@ ).

The three latest indices will be retained, also every index with no _-staging_
suffix on the alias. Other indices which start with the same string (e.g. @resources@) will be
removed by the index program after the indexing is finished - the hard disk
is not of endless size ;) .

Note: in production, always make sure that the JSON-LD context is the proper one.

h4. Small test

This will download ~5k aleph xml clobs (if not already residing in your filesystem)
and index them into elasticsearch, aliased _test-resources_ (not interfering with the
productive indexes, thus not removing any productive index).

@cd src/test/resources; bash buildAndETLTestSet.sh@

h1. License

Eclipse Public License: "http://www.eclipse.org/legal/epl-v10.html":http://www.eclipse.org/legal/epl-v10.html
